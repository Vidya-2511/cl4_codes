import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Load and preprocess data
df = pd.read_csv('/content/USA_Housing.csv')
X = df.drop(['Price', 'Address'], axis=1)
y = pd.qcut(df['Price'], q=3, labels=['Low', 'Medium', 'High'])

# Encode labels and scale features
y_enc = to_categorical(LabelEncoder().fit_transform(y))
X_scaled = StandardScaler().fit_transform(X)
X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_enc, test_size=0.2, random_state=42)

# CNN model
model = Sequential([
    Input(shape=(X_reshaped.shape[1], 1)),
    Conv1D(32, 2, activation='relu', padding='same'),
    MaxPooling1D(2),
    Conv1D(64, 2, activation='relu', padding='same'),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(3, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2,
                    callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])

# Evaluation
loss, acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {acc:.2f}")

# Extra: Predict one test sample
y_pred = np.argmax(model.predict(X_test), axis=1)
y_true = np.argmax(y_test, axis=1)
labels = ['Low', 'Medium', 'High']
i = 0
print("Predicted:", labels[y_pred[i]])
print("Actual   :", labels[y_true[i]])




import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Load and preprocess data
df = pd.read_csv('/content/USA_Housing.csv')
X = df.drop(['Price', 'Address'], axis=1)
y = pd.qcut(df['Price'], q=3, labels=['Low', 'Medium', 'High'])

# Encode labels and scale features
y_enc = to_categorical(LabelEncoder().fit_transform(y))
X_scaled = StandardScaler().fit_transform(X)
X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_enc, test_size=0.2, random_state=42)

# CNN model
model = Sequential([
    Input(shape=(X_reshaped.shape[1], 1)),
    Conv1D(32, 2, activation='relu', padding='same'),
    MaxPooling1D(2),
    Conv1D(64, 2, activation='relu', padding='same'),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(3, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2,
                    callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])

# Evaluation
loss, acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {acc:.2f}")

# Extra: Predict one test sample
y_pred = np.argmax(model.predict(X_test), axis=1)
y_true = np.argmax(y_test, axis=1)
labels = ['Low', 'Medium', 'High']
i = 0
print("Predicted:", labels[y_pred[i]])
print("Actual   :", labels[y_true[i]])
